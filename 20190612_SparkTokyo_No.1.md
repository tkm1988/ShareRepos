# Spark Tokyo 2019年参加報告

## 開催概要

###　日程

* 2019年6月12日（水）18:30〜21:00

###　会場
* Social Coding Studio of NTT Software Innovation Center
* 住所: 〒108-0023 東京都港区芝浦 3-4-1 グランパークタワー34F

### 感想

* 会場がとても綺麗
	* 宣伝して欲しいらしい

## メモ

### 0:Databricks Japanのカントリーマネージャーのご挨拶
* 日本にまだ出てきたばかり
* オフィスも探している
* 営業２名、プリセールス２名、カスタマーエンジニア等で合計９名調達予定
* 北米の次のマーケット
* データサイエンス人材は世界６位
* APAC３拠点目

### 1:セッションハイライト

* 猿田 浩輔
	* NTT DATA
* 前のセッションから次のセッションの人が並んでいたりした
* キーノートの話
* 猿田さんはDelta Lakeの話
* データ処理パイプラインの課題
	* 安全な読み書きの難しさ
	* 結果の再現性（時事刻々とデータが変わるので）
	* じゃんじゃかいれるのはいいけどバリデーションが大変
	* メタデータの肥大化でボトルネックに
* 課題解決のためのDelta Lake
	* トランザクション機能提供（HDFSの上）
	* Snapshot Isolationを使っている
	* 既存レコードアップデートはまだ非サポート
* 書き込み
	* 書き込み単位でバージョニング
	* 書き込みごとにPaquetファイルとDelta logを作成
* 読み込み
	* バージョン指定やタイムスタンプ指定で読み込み可能
* 並行制御
	* テーブル単位のみトランザクションサポート
	* 読み込みと書き込みはSnapshot Isolation
	* 書き込み同士の制御は？
	* 楽観並行制御（Delta Logの書き込みを先に完了したものだけ生きる）
	* HDFSだから実現できる
* スナップショットの構成の仕方
	* Delta Logにある直前のSnapShotを使って取捨選択
	* 形式はJSON
	* Delta Logも分散処理可能
	* インメモリーにDelta Logを持たせることで高速化
	* 一番最初は必ずHDFS
	* バージョン増えてきたときのためのチェックポイント
* チェックポイント
	* 定義した回数のSnapshotが取られると作成する
	* 毎回一から読み込む必要はない
* （質問への回答）メタデータはスケールできるのはHDFS上にDelta Logを構築している
* （質問への回答）Spark SQLを使ってPaquetファイルは見れるが、HIVEと組み合わせるの推奨されていない
* （質問への回答）


#### NET FLIXとAirbnb

* 田中 正浩
* NTT DATA
* NET FLIX
	* AWSの上でほぼ構築される
	* S3への読み書きはほぼSparkによるもの
	* 前はPigとHive
	* 実行エンジンの知識を強いるので不便
	* どうやって広めた？
		* 自分たちでSparkのブランチ切って開発するようにした
	* 挑戦
		* Executroが増えると不安定になる
		* 再現性のない障害（多分）への対処（運用設計をちゃんとやる改善
		* メモリ問題
		* ブロードキャストジョインで問題が起きやすい
		* インフラ担当によるドキュメンテーションでアプリ開発者を教育するとか
* Airbnb
	* SparkとKafkaの組み合わせ方の話
	* 2018年から６倍データが増えて６０PB
	* Kafkaで集めてSparkでHSFSに書き込んでHIVEで処理
	* KafkaのPatition数にボトルネック
	* １つのPartitionから複数のRDDを返す
	* 片寄ったトピックの処理が解決
	* OSSで公開予定

####　.NET Bindings

* 都築正宜
* NTT DATA
* .NET Bindings
* 業務ロジックは.NETが多いがビッグデータ関連ソフトは対応していないものばかり
* ScalaのAPIを真似るではなく、.NETに最適化する
* C#でPySparkみたいに書ける
* JVMとCLRの間は、Row by Rowでのシリアライゼーション、デシリアライゼーションなのでボトルネックがある

#### Spark Applicationの独自フレームワークの話

* データサイエンティストはSparkに詳しくない
	* アプリケーションコードを綺麗にしようなんて思ってない人も多い
	* 本番でテストしたり
	* そもそもテストしてなかったりが本番に…
* Webアプリケーションはフレームワークで業務ロジックに集中させる
* まだSparkにはデファクトのフレームワークがない
* ピース単位でアプリを書かせることを強制させる方針
* NTT DATAも同じ課題感を持っている
	* アプリケーション統制やCIを実現する独自フレームワークを作っている

### 2:Nested Columnsの10x性能改善

* Yahoo! Japan
* AppleのSiriチームの発表の報告
* Nested Column PruningはSpark １.０から続く話
* ファイルフォーマットで解決
* クエリリクエストについては各社で独自開発している
	* RDBMSは行指向
	* NoSQLは列指向
	* 列指向ならば不要なデータは読まないので高速化できる

### 3:MLflow + Kubeflow オンプレミスプラットフォーム事例

* Yahoo! JAPAN
* Comcastの発表の報告（Keynote）
* 課題感
	* デプロイのためのコード修正
	* 性能監視
	* モデル管理などなど
* パイプライン
	* Spark -> Kafka, Kinesis -> mlflow ->k8s
	* 前処理から学習まではSpark
	* 管理とトラッキングをmlflow
	* デプロイをKubeflow
* パッケージングはSelodon Core
	* カスタムメトリクス入れやすかった
* Ambassdorによるスケーリングとロードバランシング
	* 処理に時間がかかるモデルでも応答性能を担保した

### 4:Spark In-Memoryの発表と関連セッションの紹介

* 石崎 一明
	* IBM Research
	* Sparkのコミッターは日本で４人しかいないうちの一人
	* IBM Javaを開発していた
* 後でスライドはアップしてくれるらしい
* <https://t.co/0YiPikDGzH>

### 5:Koalasの開発状況	

* SparkのデータフレームAPI使って欲しいところだが最初はPandasを使う
* シングルノードでしか動かず大容量データは扱いづらい
* 毎週リリースしている
* 開発状況
	* DFとSeriesで30%ぐらい、一般機能などなどKoalasに実装されている
	* プルリクも結構多い
	* Sparkのキャッシュ機能をKoalas向けに提供された
	* インデキシングの向上
	* 不足するAPIをどんどん追加していく

### 6: mlflowによる機械学習のライフサイクルの管理
